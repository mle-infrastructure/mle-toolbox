# Meta Arguments: What job? What train .py file? Base config? Where to store?
meta_job_args:
    project_name: "examples"
    experiment_type: "hyperparameter-search"
    base_train_fname: "numpy_pde/run_pde_int.py"
    base_train_config:
        - "numpy_pde/pde_int_config_1.json"
        - "numpy_pde/pde_int_config_2.json"
    experiment_dir: "experiments/pde/grid"
    remote_exec_dir: "mle-toolbox/examples/"

# Parameters specific to the hyperparameter search
param_search_args:
    search_logging:
        reload_log: False
        verbose_log: True
        max_objective: True
        aggregate_seeds: "p50"
        problem_type: "final"
        eval_metrics:
            - "integral"
            - "noise"
    search_resources:
        num_search_batches: 2
        num_evals_per_batch: 2
        num_seeds_per_eval: 2
        random_seeds: [2, 4]
    search_config:
        search_type: "grid"
        search_schedule: "sync"
        search_params:
            real:
                x_0:
                    begin: 1
                    end: 10
                    bins: 2
                noise_mean:
                    begin: 0
                    end: 0.01
                    bins: 2

# Parameters specific to an individual job
single_job_args:
    job_name: "pde"
    num_gpus: 0
    num_logical_cores: 1
    log_file: "log"
    err_file: "err"
    env_name: "mle-toolbox"
    time_per_job: "00:00:05"
    extra_cmd_line_input:
        some_random_var: 1
    #partition: "ex_scioi_node"
