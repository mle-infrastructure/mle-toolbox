# Meta Arguments: What job? What train .py file? Base config? Where to store?
meta_job_args:
    project_name: "examples"
    experiment_type: "hyperparameter-search"
    base_train_fname: "numpy_pde/run_pde_int.py"
    base_train_config: "numpy_pde/pde_int_config_1.json"
    experiment_dir: "experiments/pde/smbo/"

# Parameters specific to the hyperparameter search
param_search_args:
    search_logging:
        eval_metrics:
            - "integral"
            - "noise"
    search_resources:
        num_search_batches: 3
        num_evals_per_batch: 3
        num_seeds_per_eval: 1
    search_config:
        search_type: "smbo"
        search_params:
            real:
                x_0:
                    begin: 1
                    end: 10
                    prior: "log-uniform"    # "uniform", "log-uniform"
                noise_mean:
                    begin: 0
                    end: 0.01
                    prior: "uniform"
            categorical:
                r_var:
                    - 0
                    - 1
        smbo_config:
            base_estimator: "GP"            # "GP", "RF", "ET", "GBRT"
            acq_function: "gp_hedge"        # "LCB", "EI", "PI", "gp_hedge"
            # Number init points have to be larger than batch size!
            n_initial_points: 5

# Parameters specific to an individual job
single_job_args:
    job_name: "pde"
    num_logical_cores: 1
    env_name: "mle-toolbox"
