# Meta Arguments: What job? What train .py file? Base config? Where to store?
meta_job_args:
    project_name: "examples"
    experiment_type: "hyperparameter-search"
    base_train_fname: "toy_single_objective/train.py"
    base_train_config: "toy_single_objective/base_config_1.yaml"
    experiment_dir: "experiments/toy_single/search_grid"
    report_generation: false

# Parameters specific to the hyperparameter search
param_search_args:
    search_logging:
        reload_log: False
        verbose_log: True
        max_objective: False
        aggregate_seeds: "p50"
        problem_type: "final"
        eval_metrics: "test_loss"
    search_resources:
        # num_search_batches: 4
        # num_evals_per_batch: 4
        num_total_evals: 16
        max_running_jobs: 4
        num_seeds_per_eval: 2
        random_seeds: [2, 4]
    search_config:
        search_type: "grid"
        # search_schedule: "sync"
        search_schedule: "async"
        search_params:
            real:
                lrate:
                    begin: 0.1
                    end: 0.5
                    bins: 4
            integer:
                batch_size:
                    begin: 1
                    end: 5
                    bins: 4

# Parameters specific to an individual job
single_job_args:
    job_name: "toy"
    num_logical_cores: 2
    log_file: "l-ode"
    err_file: "e-ode"
    env_name: "mle-toolbox"
    use_conda_venv: true
    time_per_job: "00:00:05"
