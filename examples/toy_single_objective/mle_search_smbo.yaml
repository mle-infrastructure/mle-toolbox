# Meta Arguments: What job? What train .py file? Base config? Where to store?
meta_job_args:
    project_name: "examples"
    experiment_type: "hyperparameter-search"
    base_train_fname: "toy_single_objective/train.py"
    base_train_config: "toy_single_objective/base_config_1.yaml"
    experiment_dir: "experiments/toy_single/smbo"

# Parameters specific to the hyperparameter search
param_search_args:
    search_logging:
        reload_log: False
        max_objective: False
        aggregate_seeds: "p50"
        problem_type: "final"
        eval_metrics: "test_loss"
    search_resources:
        num_search_batches: 3
        num_evals_per_batch: 3
        num_seeds_per_eval: 1
    search_config:
        search_type: "SMBO"
        search_params:
            real:
                lrate:
                    begin: 0.1
                    end: 0.5
                    prior: "log-uniform"    # "uniform", "log-uniform"
            integer:
                batch_size:
                    begin: 1
                    end: 5
                    prior: "uniform"
        search_config:
            metric_to_model: "test_loss"     # Which of the eval metrics to model
            base_estimator: "GP"            # "GP", "RF", "ET", "GBRT"
            acq_function: "gp_hedge"        # "LCB", "EI", "PI", "gp_hedge"
            # Number init points have to be larger than batch size!
            n_initial_points: 5

# Parameters specific to an individual job
single_job_args:
    job_name: "toy"
    num_logical_cores: 2
    log_file: "l-ode"
    err_file: "e-ode"
    env_name: "mle-toolbox"
    use_conda_venv: true
    time_per_job: "00:00:05"
