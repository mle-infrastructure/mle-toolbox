# Meta Arguments: What job? What train .py file? Base config? Where to store?
meta_job_args:
    project_name: "examples"
    experiment_type: "hyperparameter-search"
    base_train_fname: "toy_multiobj/run_toy.py"
    base_train_config: "toy_multiobj/toy_config.yaml"
    experiment_dir: "experiments/toy/nevergrad/"

# Parameters specific to the hyperparameter search
param_search_args:
    search_logging:
        eval_metrics:
            - "objective_1"
            - "objective_2"
        max_objective: false
    search_resources:
        num_search_batches: 3
        num_evals_per_batch: 3
        num_seeds_per_eval: 1
    search_config:
        search_type: "nevergrad"
        search_params:
            real:
                lrate:
                    begin: 0.01
                    end: 0.5
                    prior: "log-uniform"    # "uniform", "log-uniform"
            categorical:
                architecture:
                    - "cnn"
                    - "mlp"
            integer:
                batch_size:
                    begin: 1
                    end: 10
                    prior: "uniform"
        search_config:
            optimizer: "CMA"            # "CMA", "NGOpt"

# Parameters specific to an individual job
single_job_args:
    job_name: "pde"
    num_logical_cores: 1
    env_name: "mle-toolbox"
    use_conda_venv: true
