{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to the MLE-Infrastructure The MLE-Infrastructure is meant to provide a reproducible workflow for running Machine Learning experiments (MLE) with minimal overhead. The core consists of 4 packages: mle-logging : Experiment logging with easy multi-seed and configuration aggregation. mle-hyperopt : Hyperparameter Optimization with config export, refinement & reloading. mle-monitor : Monitor cluster/cloud VM resources & protocol experiments. mle-toolbox : Schedule & monitor experiments on Slurm, GridEngine clusters and GCP VMs. A template repository structure of an infrastructure-based project can be found here . Note : mle-logging and mle-hyperopt are standalone packages and can be used independently of the experiment scheduling utilities provided by the mle-toolbox . mle-logging mle-hyperopt mle-monitor mle-toolbox Repo / Docs Repo / Docs Repo / Docs Repo / Docs","title":"Home"},{"location":"#welcome-to-the-mle-infrastructure","text":"The MLE-Infrastructure is meant to provide a reproducible workflow for running Machine Learning experiments (MLE) with minimal overhead. The core consists of 4 packages: mle-logging : Experiment logging with easy multi-seed and configuration aggregation. mle-hyperopt : Hyperparameter Optimization with config export, refinement & reloading. mle-monitor : Monitor cluster/cloud VM resources & protocol experiments. mle-toolbox : Schedule & monitor experiments on Slurm, GridEngine clusters and GCP VMs. A template repository structure of an infrastructure-based project can be found here . Note : mle-logging and mle-hyperopt are standalone packages and can be used independently of the experiment scheduling utilities provided by the mle-toolbox . mle-logging mle-hyperopt mle-monitor mle-toolbox Repo / Docs Repo / Docs Repo / Docs Repo / Docs","title":"Welcome to the MLE-Infrastructure"},{"location":"dev/future_plans/","text":"The Future of the Toolbox You can find a couple things that need to be tackled in the issues of this project . Below is a quick overview of large milestones that could need your help: Make mle init beautiful/a smoother/more minimal experience. Better documentation via sphinx, code style and PEP setup. Automated env/container generation + clean up (delete if existing) Asynchronous job scheduling based on \"trigger event\". Core functionalities for Population-based training. Exploit Strategies Explore Strategies PBT_Manager Multi-objective SMBO (pareto front improvements). Based BOTorch with different acquisition functions. Make BaseHyperOptimisation more general/adaptive. Get rid of scikit-optimize unstable dependency. Modular adding of remote cloud VM backends: Google Cloud Platform VM instances Amazon Web Services Microsoft Azure mle-labortaory Web UI/Server. Based on streamlit Monitoring from everywhere with password protection Easy retrieval of results via click Easy report generation via click Launch experiments from UI interface More tests in test suite for core features of toolbox. Update existing integration tests Test the MLE_Logger Test log merging","title":"The Future of the Toolbox"},{"location":"dev/future_plans/#the-future-of-the-toolbox","text":"You can find a couple things that need to be tackled in the issues of this project . Below is a quick overview of large milestones that could need your help: Make mle init beautiful/a smoother/more minimal experience. Better documentation via sphinx, code style and PEP setup. Automated env/container generation + clean up (delete if existing) Asynchronous job scheduling based on \"trigger event\". Core functionalities for Population-based training. Exploit Strategies Explore Strategies PBT_Manager Multi-objective SMBO (pareto front improvements). Based BOTorch with different acquisition functions. Make BaseHyperOptimisation more general/adaptive. Get rid of scikit-optimize unstable dependency. Modular adding of remote cloud VM backends: Google Cloud Platform VM instances Amazon Web Services Microsoft Azure mle-labortaory Web UI/Server. Based on streamlit Monitoring from everywhere with password protection Easy retrieval of results via click Easy report generation via click Launch experiments from UI interface More tests in test suite for core features of toolbox. Update existing integration tests Test the MLE_Logger Test log merging","title":"The Future of the Toolbox"},{"location":"dev/infrastructure/","text":"Toolbox Infrastructure In this document you can learn everything about how to run experiments with the mle-toolbox . The mle-toolbox allows you to run different types of experiments locally or on an SGE cluster. You have to provide three inputs: An experiment/meta configuration .yaml file. A job configuration .json file. A python .py script that runs your training loop. The only things you have to do is specify your desired experiment. The toolbox automatically detects whether you start an experiment with access to multiple compute nodes. train.py takes three arguments: -config , -seed , -exp_dir This includes the standard inputs to the training function ( model_config , train_config , log_config ) but can be otherwise generalised to your applications. Jobs, Evals and Experiments Throughout the toolbox we refer to different granularities of compute loads. It helps being familiar with what these refer to (from lowest to highest level of specification): job : A single submission process on resource (e.g. one seed for one configuration) eval : A single parameter configuration which can be executed/trained for multiple seeds (individual jobs!) experiment : An entire sequence of jobs to be executed (e.g. grid search with pre/post-processing) Protocol DB Logging TBC Rich Dashboard Monitoring TBC Experiment Report Summarization TBC","title":"Toolbox Infrastructure"},{"location":"dev/infrastructure/#toolbox-infrastructure","text":"In this document you can learn everything about how to run experiments with the mle-toolbox . The mle-toolbox allows you to run different types of experiments locally or on an SGE cluster. You have to provide three inputs: An experiment/meta configuration .yaml file. A job configuration .json file. A python .py script that runs your training loop. The only things you have to do is specify your desired experiment. The toolbox automatically detects whether you start an experiment with access to multiple compute nodes. train.py takes three arguments: -config , -seed , -exp_dir This includes the standard inputs to the training function ( model_config , train_config , log_config ) but can be otherwise generalised to your applications.","title":"Toolbox Infrastructure"},{"location":"dev/infrastructure/#jobs-evals-and-experiments","text":"Throughout the toolbox we refer to different granularities of compute loads. It helps being familiar with what these refer to (from lowest to highest level of specification): job : A single submission process on resource (e.g. one seed for one configuration) eval : A single parameter configuration which can be executed/trained for multiple seeds (individual jobs!) experiment : An entire sequence of jobs to be executed (e.g. grid search with pre/post-processing)","title":"Jobs, Evals and Experiments"},{"location":"dev/infrastructure/#protocol-db-logging","text":"TBC","title":"Protocol DB Logging"},{"location":"dev/infrastructure/#rich-dashboard-monitoring","text":"TBC","title":"Rich Dashboard Monitoring"},{"location":"dev/infrastructure/#experiment-report-summarization","text":"TBC","title":"Experiment Report Summarization"},{"location":"dev/notes/","text":"Notes for Development Toolbox Philosophy Notes Biology protocol: Simply a recipe, or written design, for performing the experiment. Purpose: Formal statement which encompasses your tested hypothesis. Materials: What are major items needed to carry out your experiment? -> Git commit hash of code repository Methods: How will you set up your experiment? -> Hash of base_config.json -> Hash of meta_config.yaml Controls: What are you going to compare your results with? -> Other experiment id or None if no direct comparison Data Interpretation: What will be done with the data once it is collected? -> Generate figures from the experiment results Causality tools from Econometrics: Let's be scientific about assessing the impact of algorithmic modifications and performance comparisons. Multiple testing corrections Difference-in-difference estimation - experiment class Power assessment and p-value computation with automatic seed recommendation Notes for documentation Apply for 1000$ GCP credits: https://edu.google.com/programs/credits/research/?modal_active=none Sun Grid Engine Details on how to submit jobs with qsub More notes on the SGE system Slurm Note that slurm cluster head node allows you to only run 128 processes parallel Need to salloc into a node - figure out max running time! salloc --job-name \"InteractiveJob\" --cpus-per-task 8 --mem-per-cpu 1500 --time 20:00:00 --partition standard git seems to be not working. Remote connection?! add export var to .bashrc On Slurm it can make sense to start up a job for the experiment management in a screen/tmux session for monitoring of many jobs: screen srun --job-name \"InteractiveJob\" --cpus-per-task 1 --mem-per-cpu 1500 --time 01:00:00 --partition standard --pty bash Google Cloud Storage Checkout Google Storage Python API: https://googleapis.dev/python/storage/latest/blobs.html How to use gcloud with a proxy server https://stackoverflow.com/questions/43926668/python3-bigquery-or-google-cloud-python-through-http-proxy/43945207#43945207 How to set up Google Cloud Storage of the experiment log files Create a new project Create a new bucket in the project Set up an authentication key: https://cloud.google.com/docs/authentication/production#passing_variable pip install google-cloud-storage and export the Google authentification bath in your .bashrc script Add credentials path to cluster_config.py file & add the project + bucket name Set option whether entire experiment/figure directory should be stored! Toolbox Dependencies Pickle DB docs: https://patx.github.io/pickledb/commands.html Where to run examples & tests from Examples from the mle_toolbox/examples/ directory. Tests from the mle_toolbox/ directory Update docs homepage https://squidfunk.github.io/mkdocs-material/creating-your-site/ https://github.com/squidfunk/mkdocs-material pip install mkdocs-material mkdocs serve mkdocs gh-deploy --force GitHub Actions Billing: https://docs.github.com/en/billing/managing-billing-for-github-actions/about-billing-for-github-actions Nice visualization tools https://favicon.io/favicon-generator/ - For homepage MLE icon https://carbon.now.sh/ - for code screenshots https://github.com/homeport/termshot - for terminal output screenshots","title":"Notes for Development"},{"location":"dev/notes/#notes-for-development","text":"","title":"Notes for Development"},{"location":"dev/notes/#toolbox-philosophy-notes","text":"Biology protocol: Simply a recipe, or written design, for performing the experiment. Purpose: Formal statement which encompasses your tested hypothesis. Materials: What are major items needed to carry out your experiment? -> Git commit hash of code repository Methods: How will you set up your experiment? -> Hash of base_config.json -> Hash of meta_config.yaml Controls: What are you going to compare your results with? -> Other experiment id or None if no direct comparison Data Interpretation: What will be done with the data once it is collected? -> Generate figures from the experiment results Causality tools from Econometrics: Let's be scientific about assessing the impact of algorithmic modifications and performance comparisons. Multiple testing corrections Difference-in-difference estimation - experiment class Power assessment and p-value computation with automatic seed recommendation","title":"Toolbox Philosophy Notes"},{"location":"dev/notes/#notes-for-documentation","text":"Apply for 1000$ GCP credits: https://edu.google.com/programs/credits/research/?modal_active=none","title":"Notes for documentation"},{"location":"dev/notes/#sun-grid-engine","text":"Details on how to submit jobs with qsub More notes on the SGE system","title":"Sun Grid Engine"},{"location":"dev/notes/#slurm","text":"Note that slurm cluster head node allows you to only run 128 processes parallel Need to salloc into a node - figure out max running time! salloc --job-name \"InteractiveJob\" --cpus-per-task 8 --mem-per-cpu 1500 --time 20:00:00 --partition standard git seems to be not working. Remote connection?! add export var to .bashrc On Slurm it can make sense to start up a job for the experiment management in a screen/tmux session for monitoring of many jobs: screen srun --job-name \"InteractiveJob\" --cpus-per-task 1 --mem-per-cpu 1500 --time 01:00:00 --partition standard --pty bash","title":"Slurm"},{"location":"dev/notes/#google-cloud-storage","text":"Checkout Google Storage Python API: https://googleapis.dev/python/storage/latest/blobs.html How to use gcloud with a proxy server https://stackoverflow.com/questions/43926668/python3-bigquery-or-google-cloud-python-through-http-proxy/43945207#43945207 How to set up Google Cloud Storage of the experiment log files Create a new project Create a new bucket in the project Set up an authentication key: https://cloud.google.com/docs/authentication/production#passing_variable pip install google-cloud-storage and export the Google authentification bath in your .bashrc script Add credentials path to cluster_config.py file & add the project + bucket name Set option whether entire experiment/figure directory should be stored!","title":"Google Cloud Storage"},{"location":"dev/notes/#toolbox-dependencies","text":"Pickle DB docs: https://patx.github.io/pickledb/commands.html","title":"Toolbox Dependencies"},{"location":"dev/notes/#where-to-run-examples-tests-from","text":"Examples from the mle_toolbox/examples/ directory. Tests from the mle_toolbox/ directory","title":"Where to run examples &amp; tests from"},{"location":"dev/notes/#update-docs-homepage","text":"https://squidfunk.github.io/mkdocs-material/creating-your-site/ https://github.com/squidfunk/mkdocs-material pip install mkdocs-material mkdocs serve mkdocs gh-deploy --force","title":"Update docs homepage"},{"location":"dev/notes/#github-actions","text":"Billing: https://docs.github.com/en/billing/managing-billing-for-github-actions/about-billing-for-github-actions","title":"GitHub Actions"},{"location":"dev/notes/#nice-visualization-tools","text":"https://favicon.io/favicon-generator/ - For homepage MLE icon https://carbon.now.sh/ - for code screenshots https://github.com/homeport/termshot - for terminal output screenshots","title":"Nice visualization tools"},{"location":"dev/remote_backends/","text":"Adding Remote Backends","title":"Adding Remote Backends"},{"location":"dev/remote_backends/#adding-remote-backends","text":"","title":"Adding Remote Backends"},{"location":"dev/testing/","text":"Running The Test Suite flake8 Linting flake8 ./mle_toolbox --count --select=E9,F63,F7,F82 --show-source --statistics flake8 ./mle_toolbox --count --exit-zero --max-line-length=127 --statistics mypy Type Checking mypy mle_toolbox/. black Formatting black mle_toolbox/. --verbose Test Coverage Note : This page and content is still work in progress! Unit Tests pytest -vv tests/unit File loading: tests/unit/test_load_files.py .yaml experiment configuration .json run configuration meta_log.hdf5 hyper_log.pkl Trained models .pkl -based (sklearn) .npy -based (JAX) .pt -based (PyTorch) Experiment launch configuration file generation .qsub .sbash GCP-startup .sh file Logging Individual run assert key errors directory creation - correct file structure are files stored in correct location? is data correctly stored? Merging into meta_log.hdf5 Summary into hyper_log.pkl Reloading correctly All data types supported Tensorboard support Image storage support Experiment Protocol Logging Adding a new experiment Deleting a failed experiment Integration Tests pytest -vv tests/integration Experiment types running on different resources Single configuration: tests/integration/test_single_config.py Multiple configuration: tests/integration/test_multi_configs.py A/Synchronous Grid search experiment: tests/integration/test_grid_search.py Random search experiment: tests/integration/test_random_search.py SMBO search experiment: tests/integration/test_smbo_search.py PBT experiment Report generation Figure generation from meta-log Figure generation from hyper-log .md generation Results retrieval From GCS bucket From remote resource Toolbox initialization Config file changing Encryption ssh credentials GCS integration Pull dummy protocol DB Send results/retrieve results","title":"Running The Test Suite"},{"location":"dev/testing/#running-the-test-suite","text":"","title":"Running The Test Suite"},{"location":"dev/testing/#flake8-linting","text":"flake8 ./mle_toolbox --count --select=E9,F63,F7,F82 --show-source --statistics flake8 ./mle_toolbox --count --exit-zero --max-line-length=127 --statistics","title":"flake8 Linting"},{"location":"dev/testing/#mypy-type-checking","text":"mypy mle_toolbox/.","title":"mypy Type Checking"},{"location":"dev/testing/#black-formatting","text":"black mle_toolbox/. --verbose","title":"black Formatting"},{"location":"dev/testing/#test-coverage","text":"Note : This page and content is still work in progress!","title":"Test Coverage"},{"location":"dev/testing/#unit-tests","text":"pytest -vv tests/unit File loading: tests/unit/test_load_files.py .yaml experiment configuration .json run configuration meta_log.hdf5 hyper_log.pkl Trained models .pkl -based (sklearn) .npy -based (JAX) .pt -based (PyTorch) Experiment launch configuration file generation .qsub .sbash GCP-startup .sh file Logging Individual run assert key errors directory creation - correct file structure are files stored in correct location? is data correctly stored? Merging into meta_log.hdf5 Summary into hyper_log.pkl Reloading correctly All data types supported Tensorboard support Image storage support Experiment Protocol Logging Adding a new experiment Deleting a failed experiment","title":"Unit Tests"},{"location":"dev/testing/#integration-tests","text":"pytest -vv tests/integration Experiment types running on different resources Single configuration: tests/integration/test_single_config.py Multiple configuration: tests/integration/test_multi_configs.py A/Synchronous Grid search experiment: tests/integration/test_grid_search.py Random search experiment: tests/integration/test_random_search.py SMBO search experiment: tests/integration/test_smbo_search.py PBT experiment Report generation Figure generation from meta-log Figure generation from hyper-log .md generation Results retrieval From GCS bucket From remote resource Toolbox initialization Config file changing Encryption ssh credentials GCS integration Pull dummy protocol DB Send results/retrieve results","title":"Integration Tests"},{"location":"hyperopt/mle_hyperopt/","text":"The mle-hyperopt Package Hyperparameter optimization made easy \ud83d\ude80 The mle-hyperopt package provides a simple and intuitive API for hyperparameter optimization of your Machine Learning Experiment (MLE) pipeline. It supports real, integer & categorical search variables and single- or multi-objective optimization. Core features include the following: API Simplicity : strategy.ask() , strategy.tell() interface & space definition. Strategy Diversity : Grid, random, coordinate search, SMBO & wrapping around FAIR's nevergrad . Search Space Refinement based on the top performing configs via strategy.refine(top_k=10) . Export of configurations to execute via e.g. python train.py --config_fname config.yaml . Storage & reload search logs via strategy.save(<log_fname>) , strategy.load(<log_fname>) . For a quickstart check out the notebook blog \ud83d\udcd6. The API \ud83c\udfae from mle_hyperopt import RandomSearch # Instantiate random search class strategy = RandomSearch ( real = { \"lrate\" : { \"begin\" : 0.1 , \"end\" : 0.5 , \"prior\" : \"log-uniform\" }}, integer = { \"batch_size\" : { \"begin\" : 32 , \"end\" : 128 , \"prior\" : \"uniform\" }}, categorical = { \"arch\" : [ \"mlp\" , \"cnn\" ]}) # Simple ask - eval - tell API configs = strategy . ask ( 5 ) values = [ train_network ( ** c ) for c in configs ] strategy . tell ( configs , values ) Implemented Search Types \ud83d\udd2d Search Type Description search_config GridSearch Search over list of discrete values - RandomSearch Random search over variable ranges refine_after , refine_top_k CoordinateSearch Coordinate-wise optimization with fixed defaults order , defaults SMBOSearch Sequential model-based optimization base_estimator , acq_function , n_initial_points NevergradSearch Multi-objective nevergrad wrapper optimizer , budget_size , num_workers Variable Types & Hyperparameter Spaces \ud83c\udf0d Variable Type Space Specification real Real-valued Dict : begin , end , prior / bins (grid) integer Integer-valued Dict : begin , end , prior / bins (grid) categorical Categorical List : Values to search over Installation \u23f3 A PyPI installation is available via: pip install mle-hyperopt Alternatively, you can clone this repository and afterwards 'manually' install it: git clone https://github.com/RobertTLange/mle-hyperopt.git cd mle-hyperopt pip install -e . Further Options \ud83d\udeb4 Saving & Reloading Logs \ud83c\udfea # Storing & reloading of results from .pkl strategy . save ( \"search_log.json\" ) strategy = RandomSearch ( ... , reload_path = \"search_log.json\" ) # Or manually add info after class instantiation strategy = RandomSearch ( ... ) strategy . load ( \"search_log.json\" ) Search Decorator \ud83e\uddf6 from mle_hyperopt import hyperopt @hyperopt ( strategy_type = \"grid\" , num_search_iters = 25 , real = { \"x\" : { \"begin\" : 0. , \"end\" : 0.5 , \"bins\" : 5 }, \"y\" : { \"begin\" : 0 , \"end\" : 0.5 , \"bins\" : 5 }}) def circle ( config ): distance = abs (( config [ \"x\" ] ** 2 + config [ \"y\" ] ** 2 )) return distance strategy = circle () Storing Configuration Files \ud83d\udcd1 # Store 2 proposed configurations - eval_0.yaml, eval_1.yaml strategy . ask ( 2 , store = True ) # Store with explicit configuration filenames - conf_0.yaml, conf_1.yaml strategy . ask ( 2 , store = True , config_fnames = [ \"conf_0.yaml\" , \"conf_1.yaml\" ]) Retrieving Top Performers & Visualizing Results \ud83d\udcc9 # Get the top k best performing configurations id , configs , values = strategy . get_best ( top_k = 4 ) # Plot timeseries of best performing score over search iterations strategy . plot_best () # Print out ranking of best performers strategy . print_ranking ( top_k = 3 ) Refining the Search Space of Your Strategy \ud83e\ude93 # Refine the search space after 5 & 10 iterations based on top 2 configurations strategy = RandomSearch ( real = { \"lrate\" : { \"begin\" : 0.1 , \"end\" : 0.5 , \"prior\" : \"uniform\" }}, integer = { \"batch_size\" : { \"begin\" : 1 , \"end\" : 5 , \"prior\" : \"log-uniform\" }}, categorical = { \"arch\" : [ \"mlp\" , \"cnn\" ]}, search_config = { \"refine_after\" : [ 5 , 10 ], \"refine_top_k\" : 2 }) # Or do so manually using `refine` method strategy . tell ( ... ) strategy . refine ( top_k = 2 ) Note that the search space refinement is only implemented for random, SMBO and nevergrad-based search strategies.","title":"The `mle-hyperopt` Package"},{"location":"hyperopt/mle_hyperopt/#the-mle-hyperopt-package","text":"","title":"The mle-hyperopt Package"},{"location":"hyperopt/mle_hyperopt/#hyperparameter-optimization-made-easy","text":"The mle-hyperopt package provides a simple and intuitive API for hyperparameter optimization of your Machine Learning Experiment (MLE) pipeline. It supports real, integer & categorical search variables and single- or multi-objective optimization. Core features include the following: API Simplicity : strategy.ask() , strategy.tell() interface & space definition. Strategy Diversity : Grid, random, coordinate search, SMBO & wrapping around FAIR's nevergrad . Search Space Refinement based on the top performing configs via strategy.refine(top_k=10) . Export of configurations to execute via e.g. python train.py --config_fname config.yaml . Storage & reload search logs via strategy.save(<log_fname>) , strategy.load(<log_fname>) . For a quickstart check out the notebook blog \ud83d\udcd6.","title":"Hyperparameter optimization made easy \ud83d\ude80"},{"location":"hyperopt/mle_hyperopt/#the-api","text":"from mle_hyperopt import RandomSearch # Instantiate random search class strategy = RandomSearch ( real = { \"lrate\" : { \"begin\" : 0.1 , \"end\" : 0.5 , \"prior\" : \"log-uniform\" }}, integer = { \"batch_size\" : { \"begin\" : 32 , \"end\" : 128 , \"prior\" : \"uniform\" }}, categorical = { \"arch\" : [ \"mlp\" , \"cnn\" ]}) # Simple ask - eval - tell API configs = strategy . ask ( 5 ) values = [ train_network ( ** c ) for c in configs ] strategy . tell ( configs , values )","title":"The API \ud83c\udfae"},{"location":"hyperopt/mle_hyperopt/#implemented-search-types","text":"Search Type Description search_config GridSearch Search over list of discrete values - RandomSearch Random search over variable ranges refine_after , refine_top_k CoordinateSearch Coordinate-wise optimization with fixed defaults order , defaults SMBOSearch Sequential model-based optimization base_estimator , acq_function , n_initial_points NevergradSearch Multi-objective nevergrad wrapper optimizer , budget_size , num_workers","title":"Implemented Search Types    \ud83d\udd2d"},{"location":"hyperopt/mle_hyperopt/#variable-types-hyperparameter-spaces","text":"Variable Type Space Specification real Real-valued Dict : begin , end , prior / bins (grid) integer Integer-valued Dict : begin , end , prior / bins (grid) categorical Categorical List : Values to search over","title":"Variable Types &amp; Hyperparameter Spaces \ud83c\udf0d"},{"location":"hyperopt/mle_hyperopt/#installation","text":"A PyPI installation is available via: pip install mle-hyperopt Alternatively, you can clone this repository and afterwards 'manually' install it: git clone https://github.com/RobertTLange/mle-hyperopt.git cd mle-hyperopt pip install -e .","title":"Installation \u23f3"},{"location":"hyperopt/mle_hyperopt/#further-options","text":"","title":"Further Options \ud83d\udeb4"},{"location":"hyperopt/mle_hyperopt/#saving-reloading-logs","text":"# Storing & reloading of results from .pkl strategy . save ( \"search_log.json\" ) strategy = RandomSearch ( ... , reload_path = \"search_log.json\" ) # Or manually add info after class instantiation strategy = RandomSearch ( ... ) strategy . load ( \"search_log.json\" )","title":"Saving &amp; Reloading Logs \ud83c\udfea"},{"location":"hyperopt/mle_hyperopt/#search-decorator","text":"from mle_hyperopt import hyperopt @hyperopt ( strategy_type = \"grid\" , num_search_iters = 25 , real = { \"x\" : { \"begin\" : 0. , \"end\" : 0.5 , \"bins\" : 5 }, \"y\" : { \"begin\" : 0 , \"end\" : 0.5 , \"bins\" : 5 }}) def circle ( config ): distance = abs (( config [ \"x\" ] ** 2 + config [ \"y\" ] ** 2 )) return distance strategy = circle ()","title":"Search Decorator \ud83e\uddf6"},{"location":"hyperopt/mle_hyperopt/#storing-configuration-files","text":"# Store 2 proposed configurations - eval_0.yaml, eval_1.yaml strategy . ask ( 2 , store = True ) # Store with explicit configuration filenames - conf_0.yaml, conf_1.yaml strategy . ask ( 2 , store = True , config_fnames = [ \"conf_0.yaml\" , \"conf_1.yaml\" ])","title":"Storing Configuration Files \ud83d\udcd1"},{"location":"hyperopt/mle_hyperopt/#retrieving-top-performers-visualizing-results","text":"# Get the top k best performing configurations id , configs , values = strategy . get_best ( top_k = 4 ) # Plot timeseries of best performing score over search iterations strategy . plot_best () # Print out ranking of best performers strategy . print_ranking ( top_k = 3 )","title":"Retrieving Top Performers &amp; Visualizing Results \ud83d\udcc9"},{"location":"hyperopt/mle_hyperopt/#refining-the-search-space-of-your-strategy","text":"# Refine the search space after 5 & 10 iterations based on top 2 configurations strategy = RandomSearch ( real = { \"lrate\" : { \"begin\" : 0.1 , \"end\" : 0.5 , \"prior\" : \"uniform\" }}, integer = { \"batch_size\" : { \"begin\" : 1 , \"end\" : 5 , \"prior\" : \"log-uniform\" }}, categorical = { \"arch\" : [ \"mlp\" , \"cnn\" ]}, search_config = { \"refine_after\" : [ 5 , 10 ], \"refine_top_k\" : 2 }) # Or do so manually using `refine` method strategy . tell ( ... ) strategy . refine ( top_k = 2 ) Note that the search space refinement is only implemented for random, SMBO and nevergrad-based search strategies.","title":"Refining the Search Space of Your Strategy \ud83e\ude93"},{"location":"logging/mle_logging/","text":"The mle-logging Package Experiment logging made easy \ud83d\udcd6 Each Python-based experiment is assumed to use a custom logger: The MLELogger . This enables the standardization needed to automatically aggregate multiple random runs and to log performance across hyperparameter searches. For a quickstart checkout the notebook blog \ud83d\ude80 The API \ud83c\udfae from mle_logging import MLELogger # Instantiate logging to experiment_dir log = MLELogger ( time_to_track = [ 'num_updates' , 'num_epochs' ], what_to_track = [ 'train_loss' , 'test_loss' ], experiment_dir = \"experiment_dir/\" , model_type = 'torch' ) time_tic = { 'num_updates' : 10 , 'num_epochs' : 1 } stats_tic = { 'train_loss' : 0.1234 , 'test_loss' : 0.1235 } # Update the log with collected data & save it to .hdf5 log . update ( time_tic , stats_tic ) log . save () You can also log model checkpoints, matplotlib figures and other .pkl compatible objects. # Save a model (torch, tensorflow, sklearn, jax, numpy) import torchvision.models as models model = models . resnet18 () log . save_model ( model ) # Save a matplotlib figure as .png fig , ax = plt . subplots () log . save_plot ( fig ) # You can also save (somewhat) arbitrary objects .pkl some_dict = { \"hi\" : \"there\" } log . save_extra ( some_dict ) Or do everything in a single line... log . update ( time_tic , stats_tic , model , fig , extra , save = True ) File Structure & Re-Loading \ud83d\udcda The MLELogger will create a nested directory, which looks as follows: experiment_dir \u251c\u2500\u2500 extra: Stores saved .pkl object files \u251c\u2500\u2500 figures: Stores saved .png figures \u251c\u2500\u2500 logs: Stores .hdf5 log files (meta, stats, time) \u251c\u2500\u2500 models: Stores different model checkpoints \u251c\u2500\u2500 init: Stores initial checkpoint \u251c\u2500\u2500 final: Stores most recent checkpoint \u251c\u2500\u2500 every_k: Stores every k-th checkpoint provided in update \u251c\u2500\u2500 top_k: Stores portfolio of top-k checkpoints based on performance \u251c\u2500\u2500 tboards: Stores tensorboards for model checkpointing \u251c\u2500\u2500 <config_name>.json: Copy of configuration file (if provided) For visualization and post-processing load the results via from mle_logging import load_log log_out = load_log ( \"experiment_dir/\" ) # The results can be accessed via meta, stats and time keys # >>> log_out.meta.keys() # odict_keys(['experiment_dir', 'extra_storage_paths', 'fig_storage_paths', 'log_paths', 'model_ckpt', 'model_type']) # >>> log_out.stats.keys() # odict_keys(['test_loss', 'train_loss']) # >>> log_out.time.keys() # odict_keys(['time', 'num_epochs', 'num_updates', 'time_elapsed']) If an experiment was aborted, you can reload and continue the previous run via the reload=True option: log = MLELogger ( time_to_track = [ 'num_updates' , 'num_epochs' ], what_to_track = [ 'train_loss' , 'test_loss' ], experiment_dir = \"experiment_dir/\" , model_type = 'torch' , reload = True ) Installation \u23f3 A PyPI installation is available via: pip install mle-logging Alternatively, you can clone this repository and afterwards 'manually' install it: git clone https://github.com/RobertTLange/mle-logging.git cd mle-logging pip install -e . Advanced Options \ud83d\udeb4 Merging Multiple Logs \ud83d\udc6b Merging Multiple Random Seeds \ud83c\udf31 + \ud83c\udf31 from mle_logging import merge_seed_logs merge_seed_logs ( \"multi_seed.hdf\" , \"experiment_dir/\" ) log_out = load_log ( \"experiment_dir/\" ) # >>> log.eval_ids # ['seed_1', 'seed_2'] Merging Multiple Configurations \ud83d\udd16 + \ud83d\udd16 from mle_logging import merge_config_logs , load_meta_log merge_config_logs ( experiment_dir = \"experiment_dir/\" , all_run_ids = [ \"config_1\" , \"config_2\" ]) meta_log = load_meta_log ( \"multi_config_dir/meta_log.hdf5\" ) # >>> log.eval_ids # ['config_2', 'config_1'] # >>> meta_log.config_1.stats.test_loss.keys() # odict_keys(['mean', 'std', 'p50', 'p10', 'p25', 'p75', 'p90'])) Plotting of Logs \ud83e\uddd1\u200d\ud83c\udfa8 meta_log = load_meta_log ( \"multi_config_dir/meta_log.hdf5\" ) meta_log . plot ( \"train_loss\" , \"num_updates\" ) Storing Checkpoint Portfolios \ud83d\udcc2 Logging every k-th checkpoint update \u2757 \u23e9 ... \u23e9 \u2757 # Save every second checkpoint provided in log.update (stored in models/every_k) log = MLELogger ( time_to_track = [ 'num_updates' , 'num_epochs' ], what_to_track = [ 'train_loss' , 'test_loss' ], experiment_dir = 'every_k_dir/' , model_type = 'torch' , ckpt_time_to_track = 'num_updates' , save_every_k_ckpt = 2 ) Logging top-k checkpoints based on metric \ud83d\udd31 # Save top-3 checkpoints provided in log.update (stored in models/top_k) # Based on minimizing the test_loss metric log = MLELogger ( time_to_track = [ 'num_updates' , 'num_epochs' ], what_to_track = [ 'train_loss' , 'test_loss' ], experiment_dir = \"top_k_dir/\" , model_type = 'torch' , ckpt_time_to_track = 'num_updates' , save_top_k_ckpt = 3 , top_k_metric_name = \"test_loss\" , top_k_minimize_metric = True )","title":"The `mle-logging` Package"},{"location":"logging/mle_logging/#the-mle-logging-package","text":"","title":"The mle-logging Package"},{"location":"logging/mle_logging/#experiment-logging-made-easy","text":"Each Python-based experiment is assumed to use a custom logger: The MLELogger . This enables the standardization needed to automatically aggregate multiple random runs and to log performance across hyperparameter searches. For a quickstart checkout the notebook blog \ud83d\ude80","title":"Experiment logging made easy \ud83d\udcd6"},{"location":"logging/mle_logging/#the-api","text":"from mle_logging import MLELogger # Instantiate logging to experiment_dir log = MLELogger ( time_to_track = [ 'num_updates' , 'num_epochs' ], what_to_track = [ 'train_loss' , 'test_loss' ], experiment_dir = \"experiment_dir/\" , model_type = 'torch' ) time_tic = { 'num_updates' : 10 , 'num_epochs' : 1 } stats_tic = { 'train_loss' : 0.1234 , 'test_loss' : 0.1235 } # Update the log with collected data & save it to .hdf5 log . update ( time_tic , stats_tic ) log . save () You can also log model checkpoints, matplotlib figures and other .pkl compatible objects. # Save a model (torch, tensorflow, sklearn, jax, numpy) import torchvision.models as models model = models . resnet18 () log . save_model ( model ) # Save a matplotlib figure as .png fig , ax = plt . subplots () log . save_plot ( fig ) # You can also save (somewhat) arbitrary objects .pkl some_dict = { \"hi\" : \"there\" } log . save_extra ( some_dict ) Or do everything in a single line... log . update ( time_tic , stats_tic , model , fig , extra , save = True )","title":"The API \ud83c\udfae"},{"location":"logging/mle_logging/#file-structure-re-loading","text":"The MLELogger will create a nested directory, which looks as follows: experiment_dir \u251c\u2500\u2500 extra: Stores saved .pkl object files \u251c\u2500\u2500 figures: Stores saved .png figures \u251c\u2500\u2500 logs: Stores .hdf5 log files (meta, stats, time) \u251c\u2500\u2500 models: Stores different model checkpoints \u251c\u2500\u2500 init: Stores initial checkpoint \u251c\u2500\u2500 final: Stores most recent checkpoint \u251c\u2500\u2500 every_k: Stores every k-th checkpoint provided in update \u251c\u2500\u2500 top_k: Stores portfolio of top-k checkpoints based on performance \u251c\u2500\u2500 tboards: Stores tensorboards for model checkpointing \u251c\u2500\u2500 <config_name>.json: Copy of configuration file (if provided) For visualization and post-processing load the results via from mle_logging import load_log log_out = load_log ( \"experiment_dir/\" ) # The results can be accessed via meta, stats and time keys # >>> log_out.meta.keys() # odict_keys(['experiment_dir', 'extra_storage_paths', 'fig_storage_paths', 'log_paths', 'model_ckpt', 'model_type']) # >>> log_out.stats.keys() # odict_keys(['test_loss', 'train_loss']) # >>> log_out.time.keys() # odict_keys(['time', 'num_epochs', 'num_updates', 'time_elapsed']) If an experiment was aborted, you can reload and continue the previous run via the reload=True option: log = MLELogger ( time_to_track = [ 'num_updates' , 'num_epochs' ], what_to_track = [ 'train_loss' , 'test_loss' ], experiment_dir = \"experiment_dir/\" , model_type = 'torch' , reload = True )","title":"File Structure &amp; Re-Loading \ud83d\udcda"},{"location":"logging/mle_logging/#installation","text":"A PyPI installation is available via: pip install mle-logging Alternatively, you can clone this repository and afterwards 'manually' install it: git clone https://github.com/RobertTLange/mle-logging.git cd mle-logging pip install -e .","title":"Installation \u23f3"},{"location":"logging/mle_logging/#advanced-options","text":"","title":"Advanced Options \ud83d\udeb4"},{"location":"logging/mle_logging/#merging-multiple-logs","text":"Merging Multiple Random Seeds \ud83c\udf31 + \ud83c\udf31 from mle_logging import merge_seed_logs merge_seed_logs ( \"multi_seed.hdf\" , \"experiment_dir/\" ) log_out = load_log ( \"experiment_dir/\" ) # >>> log.eval_ids # ['seed_1', 'seed_2'] Merging Multiple Configurations \ud83d\udd16 + \ud83d\udd16 from mle_logging import merge_config_logs , load_meta_log merge_config_logs ( experiment_dir = \"experiment_dir/\" , all_run_ids = [ \"config_1\" , \"config_2\" ]) meta_log = load_meta_log ( \"multi_config_dir/meta_log.hdf5\" ) # >>> log.eval_ids # ['config_2', 'config_1'] # >>> meta_log.config_1.stats.test_loss.keys() # odict_keys(['mean', 'std', 'p50', 'p10', 'p25', 'p75', 'p90']))","title":"Merging Multiple Logs \ud83d\udc6b"},{"location":"logging/mle_logging/#plotting-of-logs","text":"meta_log = load_meta_log ( \"multi_config_dir/meta_log.hdf5\" ) meta_log . plot ( \"train_loss\" , \"num_updates\" )","title":"Plotting of Logs \ud83e\uddd1\u200d\ud83c\udfa8"},{"location":"logging/mle_logging/#storing-checkpoint-portfolios","text":"Logging every k-th checkpoint update \u2757 \u23e9 ... \u23e9 \u2757 # Save every second checkpoint provided in log.update (stored in models/every_k) log = MLELogger ( time_to_track = [ 'num_updates' , 'num_epochs' ], what_to_track = [ 'train_loss' , 'test_loss' ], experiment_dir = 'every_k_dir/' , model_type = 'torch' , ckpt_time_to_track = 'num_updates' , save_every_k_ckpt = 2 ) Logging top-k checkpoints based on metric \ud83d\udd31 # Save top-3 checkpoints provided in log.update (stored in models/top_k) # Based on minimizing the test_loss metric log = MLELogger ( time_to_track = [ 'num_updates' , 'num_epochs' ], what_to_track = [ 'train_loss' , 'test_loss' ], experiment_dir = \"top_k_dir/\" , model_type = 'torch' , ckpt_time_to_track = 'num_updates' , save_top_k_ckpt = 3 , top_k_metric_name = \"test_loss\" , top_k_minimize_metric = True )","title":"Storing Checkpoint Portfolios \ud83d\udcc2"},{"location":"monitor/mle_monitor/","text":"The mle-monitor Package Resource monitoring made easy \ud83d\udcfa","title":"The `mle-monitor` Package"},{"location":"monitor/mle_monitor/#the-mle-monitor-package","text":"","title":"The mle-monitor Package"},{"location":"monitor/mle_monitor/#resource-monitoring-made-easy","text":"","title":"Resource monitoring made easy \ud83d\udcfa"},{"location":"setup/configuration/","text":"Toolbox Configuration By default the toolbox will run locally and without any GCS bucket backup of your experiment results. Furthermore, a lightweight PickleDB protocol database of your experiments will not be synced with the cloud version. In the following, we walkthrough how to Enable the execution of jobs on remote resources (cluster/storage) from your local machine or from the resource itself. Enable the backing up of your experiment results in a GCS bucket. Enable the backing up of a PickleDB experiment meta log in a GCS bucket. Enable resource monitoring and online dashboard visualization . Enable slack bot notifications for experiment completion and reporting. Note : There are two ways to perform the toolbox configuration: After installation execute mle init . This will walk you through all configuration steps in your CLI and save your configuration in ~/mle_config.toml . Manually edit the config_template.toml template. Move/rename the template to your home directory via mv config_template.toml ~/mle_config.toml . The configuration procedure consists of 3 optional steps, which depend on your needs: Set whether to store all results & your database locally or remote in a GCS bucket. Add SGE and/or Slurm credentials & cluster-specific details (headnode, partitions, proxy server, etc.). Add the GCP project, GCS bucket name and database filename to store your results. Remote Resource Execution The toolbox supports the usage of multiple different compute resources. This includes your local machine, but more importantly remote clusters such as the prominent slurm and grid engine schedulers and Google Cloud Platform VMs. In order to be able to schedule remote jobs from your local machine or retrieve the results from the cluster, you will have to provide your credentials, headnode and partition names as well as some default arguments for jobs: #------------------------------------------------------------------------------# # 2. Configuration for Slurm Cluster #------------------------------------------------------------------------------# [slurm] # Slurm credentials - Only if you want to retrieve results from cluster [slurm.credentials] user_name = '<slurm-user-name>' password = '<slurm-password>' aes_key = '<aes-key>' # Slurm cluster information - Job scheduling, monitoring & retrieval [slurm.info] # Headnode name & partitions to monitor/run jobs on head_names = [ '<headnode1>' ] node_reg_exp = [ '<nodes-to-monitor1>' ] partitions = [ '<partition1>' ] # Info for results retrieval & internet tunneling if local launch main_server_name = '<main-server-ip>' jump_server_name = '<jump-host-ip>' ssh_port = 22 # Add proxy server for internet connection if needed! http_proxy = \"http://<slurm_headnode>:3128/\" https_proxy = \"http://<slurm_headnode>:3128/\" # Default Slurm job arguments (if not supplied in job .yaml config) [slurm.default_job_args] num_logical_cores = 2 partition = '<partition1>' job_name = 'temp' log_file = 'log' err_file = 'err' env_name = '<mle-default-env>' Google Cloud Platform VM Jobs If you want to use the toolbox for orchestrating GCP VMs, you will need to have set up the Google Cloud SDK . This will work as follows: curl -O https://dl.google.com/dl/cloudsdk/channels/rapid/downloads/google-cloud-sdk-353.0.0-linux-x86_64.tar.gz ./google-cloud-sdk/install.sh ./google-cloud-sdk/bin/gcloud init At initialization you will be required to select a GCP project. Internally the toolbox will call different gcloud commands to launch new VMs and/or monitor the status of running jobs. Google Cloud Storage Backups If you choose so, the toolbox will sync a local version of your experiment protocol database with a GCS bucket. Furthermore, the results of your experiments will be zipped and stored via a unique hash. You can afterwards use mle retrieve in order to retrieve these backed up results from the bucket. These functionalities rely on google-cloud-storage and you having set your GOOGLE_APPLICATION_CREDENTIALS . You have to follow four steps: Create your .json key file here . Name it ~/gcp_mle_key.json Set the path via adding export GOOGLE_APPLICATION_CREDENTIALS = ~/gcp_mle_key.json to your .bashrc or .zshrc file. Create a GCP project and a storage bucket. Have a look here for how to do this. Provide the path, GCP project and bucket to store your results in your ~/mle_config.toml configuration: #------------------------------------------------------------------------------# # 4. GCP Config - Credentials, Project + Buffer for Meta-Experiment Protocol #------------------------------------------------------------------------------# [gcp] # Set absolute path to the GCloud .json credentials - on Slurm/SGE cluster slurm_credentials_path = \"~/<slurm_path_to_gcloud_credentials>.json\" sge_credentials_path = \"~/<sge_path_to_gcloud_credentials>.json\" # Set GCloud project and bucket name for storage/compute instances project_name = \"<gcloud_project_name>\" bucket_name = \"<gcloud_bucket_name>\" PickleDB Experiment Logging We rely on pickleDB for logging meta data of your experiments. It is a lightweight alternative to a full NoSQL-style database, which would require more setup. Instead, pickleDB will create a simple json-style file storing the experiment purpose, id, compute resource, configuration, etc.. You can change the default storage paths for the local and remote version in your ~/mle_config.toml : #------------------------------------------------------------------------------# # 1. General Toolbox Configuration - Verbosity + Whether to use GCS Storage #------------------------------------------------------------------------------# [general] # Local filename to store protocol DB in local_protocol_fname = '~/local_mle_protocol.db' ... #------------------------------------------------------------------------------# # 4. GCP Config - Credentials, Project + Buffer for Meta-Experiment Protocol #------------------------------------------------------------------------------# [gcp] ... # Filename to retrieve from gcloud bucket & where to store protocol_fname = \"gcloud_mle_protocol.db\" Resource Dashboard Monitoring mle monitor - add how to set monitored partition/nodes/etc. Slack Bot Notification If you want to, you can add slack notifications using the slack-clusterbot . If you want to learn more about how to set it up, checkout the wiki documentation . To make it short, you need to create a Bot User OAuth Access Token for your slack workspace and afterwards add this to your mle_config.toml : #------------------------------------------------------------------------------# # 5. Slack Bot Config - OAuth Access Token & Config Path # https://github.com/sprekelerlab/slack-clusterbot/wiki/Installation # OPTIONAL: Only required if you want to slack notifications/updates #------------------------------------------------------------------------------# [slack] # Set authentication token and default username messages are sent to slack_token = \"xoxb-325096705189-891732090737-5Kx0njelNmBdMn1OXSCkrH2P\" user_name = \"Robert Lange\"","title":"Toolbox Configuration"},{"location":"setup/configuration/#toolbox-configuration","text":"By default the toolbox will run locally and without any GCS bucket backup of your experiment results. Furthermore, a lightweight PickleDB protocol database of your experiments will not be synced with the cloud version. In the following, we walkthrough how to Enable the execution of jobs on remote resources (cluster/storage) from your local machine or from the resource itself. Enable the backing up of your experiment results in a GCS bucket. Enable the backing up of a PickleDB experiment meta log in a GCS bucket. Enable resource monitoring and online dashboard visualization . Enable slack bot notifications for experiment completion and reporting. Note : There are two ways to perform the toolbox configuration: After installation execute mle init . This will walk you through all configuration steps in your CLI and save your configuration in ~/mle_config.toml . Manually edit the config_template.toml template. Move/rename the template to your home directory via mv config_template.toml ~/mle_config.toml . The configuration procedure consists of 3 optional steps, which depend on your needs: Set whether to store all results & your database locally or remote in a GCS bucket. Add SGE and/or Slurm credentials & cluster-specific details (headnode, partitions, proxy server, etc.). Add the GCP project, GCS bucket name and database filename to store your results.","title":"Toolbox Configuration"},{"location":"setup/configuration/#remote-resource-execution","text":"The toolbox supports the usage of multiple different compute resources. This includes your local machine, but more importantly remote clusters such as the prominent slurm and grid engine schedulers and Google Cloud Platform VMs. In order to be able to schedule remote jobs from your local machine or retrieve the results from the cluster, you will have to provide your credentials, headnode and partition names as well as some default arguments for jobs: #------------------------------------------------------------------------------# # 2. Configuration for Slurm Cluster #------------------------------------------------------------------------------# [slurm] # Slurm credentials - Only if you want to retrieve results from cluster [slurm.credentials] user_name = '<slurm-user-name>' password = '<slurm-password>' aes_key = '<aes-key>' # Slurm cluster information - Job scheduling, monitoring & retrieval [slurm.info] # Headnode name & partitions to monitor/run jobs on head_names = [ '<headnode1>' ] node_reg_exp = [ '<nodes-to-monitor1>' ] partitions = [ '<partition1>' ] # Info for results retrieval & internet tunneling if local launch main_server_name = '<main-server-ip>' jump_server_name = '<jump-host-ip>' ssh_port = 22 # Add proxy server for internet connection if needed! http_proxy = \"http://<slurm_headnode>:3128/\" https_proxy = \"http://<slurm_headnode>:3128/\" # Default Slurm job arguments (if not supplied in job .yaml config) [slurm.default_job_args] num_logical_cores = 2 partition = '<partition1>' job_name = 'temp' log_file = 'log' err_file = 'err' env_name = '<mle-default-env>'","title":"Remote Resource Execution"},{"location":"setup/configuration/#google-cloud-platform-vm-jobs","text":"If you want to use the toolbox for orchestrating GCP VMs, you will need to have set up the Google Cloud SDK . This will work as follows: curl -O https://dl.google.com/dl/cloudsdk/channels/rapid/downloads/google-cloud-sdk-353.0.0-linux-x86_64.tar.gz ./google-cloud-sdk/install.sh ./google-cloud-sdk/bin/gcloud init At initialization you will be required to select a GCP project. Internally the toolbox will call different gcloud commands to launch new VMs and/or monitor the status of running jobs.","title":"Google Cloud Platform VM Jobs"},{"location":"setup/configuration/#google-cloud-storage-backups","text":"If you choose so, the toolbox will sync a local version of your experiment protocol database with a GCS bucket. Furthermore, the results of your experiments will be zipped and stored via a unique hash. You can afterwards use mle retrieve in order to retrieve these backed up results from the bucket. These functionalities rely on google-cloud-storage and you having set your GOOGLE_APPLICATION_CREDENTIALS . You have to follow four steps: Create your .json key file here . Name it ~/gcp_mle_key.json Set the path via adding export GOOGLE_APPLICATION_CREDENTIALS = ~/gcp_mle_key.json to your .bashrc or .zshrc file. Create a GCP project and a storage bucket. Have a look here for how to do this. Provide the path, GCP project and bucket to store your results in your ~/mle_config.toml configuration: #------------------------------------------------------------------------------# # 4. GCP Config - Credentials, Project + Buffer for Meta-Experiment Protocol #------------------------------------------------------------------------------# [gcp] # Set absolute path to the GCloud .json credentials - on Slurm/SGE cluster slurm_credentials_path = \"~/<slurm_path_to_gcloud_credentials>.json\" sge_credentials_path = \"~/<sge_path_to_gcloud_credentials>.json\" # Set GCloud project and bucket name for storage/compute instances project_name = \"<gcloud_project_name>\" bucket_name = \"<gcloud_bucket_name>\"","title":"Google Cloud Storage Backups"},{"location":"setup/configuration/#pickledb-experiment-logging","text":"We rely on pickleDB for logging meta data of your experiments. It is a lightweight alternative to a full NoSQL-style database, which would require more setup. Instead, pickleDB will create a simple json-style file storing the experiment purpose, id, compute resource, configuration, etc.. You can change the default storage paths for the local and remote version in your ~/mle_config.toml : #------------------------------------------------------------------------------# # 1. General Toolbox Configuration - Verbosity + Whether to use GCS Storage #------------------------------------------------------------------------------# [general] # Local filename to store protocol DB in local_protocol_fname = '~/local_mle_protocol.db' ... #------------------------------------------------------------------------------# # 4. GCP Config - Credentials, Project + Buffer for Meta-Experiment Protocol #------------------------------------------------------------------------------# [gcp] ... # Filename to retrieve from gcloud bucket & where to store protocol_fname = \"gcloud_mle_protocol.db\"","title":"PickleDB Experiment Logging"},{"location":"setup/configuration/#resource-dashboard-monitoring","text":"mle monitor - add how to set monitored partition/nodes/etc.","title":"Resource Dashboard Monitoring"},{"location":"setup/configuration/#slack-bot-notification","text":"If you want to, you can add slack notifications using the slack-clusterbot . If you want to learn more about how to set it up, checkout the wiki documentation . To make it short, you need to create a Bot User OAuth Access Token for your slack workspace and afterwards add this to your mle_config.toml : #------------------------------------------------------------------------------# # 5. Slack Bot Config - OAuth Access Token & Config Path # https://github.com/sprekelerlab/slack-clusterbot/wiki/Installation # OPTIONAL: Only required if you want to slack notifications/updates #------------------------------------------------------------------------------# [slack] # Set authentication token and default username messages are sent to slack_token = \"xoxb-325096705189-891732090737-5Kx0njelNmBdMn1OXSCkrH2P\" user_name = \"Robert Lange\"","title":"Slack Bot Notification"},{"location":"setup/installation/","text":"Installation If you want to use the toolbox on your local machine or on a GCP cloud VM follow the instructions locally. Otherwise do so on your respective cluster resource (Slurm/SGE). PyPI Installation The latest release of the toolbox can be installed via PyPI : pip install mle-toolbox This will by default also install the subpackages mle-logging , mle-hyperopt & mle-monitor . Note that all of these are also available as standalone PyPI installations. GitHub Installation If you want the most recent version with all pre-release commits, you can clone the repository and afterwards 'manually' install it: git clone https://github.com/RobertTLange/mle-toolbox.git cd mle-toolbox pip install -e . By default this will only install the minimal dependencies (not including special packages for hyperparameter optimization such as scikit-optimize , statsmodels , etc.). To get all requirements for tests or examples you will need to install additional requirements : pip install -r requirements/requirements-test.txt Future Installation Support In the future I plan to add an installation via conda-forge and Docker/Singularity images for the mle-toolbox .","title":"Installation"},{"location":"setup/installation/#installation","text":"If you want to use the toolbox on your local machine or on a GCP cloud VM follow the instructions locally. Otherwise do so on your respective cluster resource (Slurm/SGE).","title":"Installation"},{"location":"setup/installation/#pypi-installation","text":"The latest release of the toolbox can be installed via PyPI : pip install mle-toolbox This will by default also install the subpackages mle-logging , mle-hyperopt & mle-monitor . Note that all of these are also available as standalone PyPI installations.","title":"PyPI Installation"},{"location":"setup/installation/#github-installation","text":"If you want the most recent version with all pre-release commits, you can clone the repository and afterwards 'manually' install it: git clone https://github.com/RobertTLange/mle-toolbox.git cd mle-toolbox pip install -e . By default this will only install the minimal dependencies (not including special packages for hyperparameter optimization such as scikit-optimize , statsmodels , etc.). To get all requirements for tests or examples you will need to install additional requirements : pip install -r requirements/requirements-test.txt","title":"GitHub Installation"},{"location":"setup/installation/#future-installation-support","text":"In the future I plan to add an installation via conda-forge and Docker/Singularity images for the mle-toolbox .","title":"Future Installation Support"},{"location":"setup/template/","text":"Project Template In order to get a feeling for how an experiment based on the toolbox utilities may look like, checkout the project template repository . General Directory Structure mle-project-template \u251c\u2500\u2500 configs: Training configurations (base and cluster searches) \u251c\u2500\u2500 train: .json training configuration \u251c\u2500\u2500 cluster: .yaml experiment configuration \u251c\u2500\u2500 docs: Some work-in-progress notes/documentation \u251c\u2500\u2500 experiments: Main directory storing results \u251c\u2500\u2500 notebooks: Sanity checks & result visualization \u251c\u2500\u2500 01_viz_results.ipynb: Visualize some results \u251c\u2500\u2500 utils: Helper functions (data generation, networks, training helpers) \u251c\u2500\u2500 cluster_exec.sh: Main training loop \u251c\u2500\u2500 mle_bash.sh: Main training loop as bash program \u251c\u2500\u2500 mle_python.py: Main training loop as python program \u251c\u2500\u2500 Readme.md: Documentation \u251c\u2500\u2500 requirements.txt: Dependencies .yaml experiment configuration The .yaml file specifies what type of experiment you want to run. It consists of two core ingredients ( meta_job_args and single_job_args ) which have to be provided with every experiment type: # Meta Arguments: What job? What train .py file? # Base .json config? Where to store? meta_job_args : # Choose a project name used for logging your experiments project_name : \"<project_name>\" # Specifies what experiment to run. Can be one of the following: # 'single-config', 'multiple-configs', 'hyperparameter-search', # 'population-based-training' experiment_type : \"<experiment_type>\" base_train_fname : \"mle_python.py\" base_train_config : \"train/<base_config>.json\" experiment_dir : \"experiments/\" # Parameters for individual job: 2 logical cores single_job_args : job_name : \"ode\" num_logical_cores : 2 log_file : \"log\" err_file : \"err\" env_name : \"mle-toolbox\" They provide the most general information required to launch a single job that will execute mle_python.py on a resource with two logical cores. Additionally and depending on the settings you want to run please provide one of the following additional ingredients: Pre/Post-Processing : pre_processing_args and/or post_processing_args Multiple Configurations : multi_config_args Grid/Random Search/SMBO : param_search_args Population-Based Training : pbt_args .json training configuration The .json file, on the other hand, specifies the train_config , log_config and (optionally) model_config , which are provided to a job. They can be easily accessed via the MLExperiment class instance (see below): { # Trai n i n g co nf igura t io n : Adap te d by hyperparame ter search \"train_config\" : { \"learning_rate\" : 3e-04 , ... }, # Model co nf igura t io n : Layer i nf o (i f t here was a net t o tra i n ) \"model_config\" : { \"num_hidden_layers\" : 2 , ... }, # Loggi n g co nf igura t io n : Wha t t o log/pri nt & tens orboard f ile na me \"log_config\" : { \"time_to_track\" : [ \"timestamp1\" ], # Var na mes o f t imes ta mps \"what_to_track\" : [ \"metric1\" , \"metric2\" ], # Var na mes o f s tats vars \"time_to_print\" : [ \"timestamp1\" ], # Time var na mes t o pri nt \"what_to_print\" : [ \"metric1\" ], # S tats var na mes t o pri nt \"print_every_k_updates\" : 1 , # How o ften t o pri nt \"overwrite_experiment_dir\" : 1 } # Whe t her t o overwri te exis t i n g dir } Importantly, when launching a grid search experiment the toolbox will copy the base configuration file and modify the variables in train_config which you intend to search over. .py training script file # Import MLE wrapper processing cmd inputs and logging from mle_toolbox import MLExperiment def main ( mle ): \"\"\" Main Training Loop Function. \"\"\" # Setup your experiment - e.g. build a network with `mle.model_config` model = build_model ( ** mle . model_config ) # Run the main training loop for t in range ( mle . train_config . num_steps ): # Perform the one-step optimization update metric1 , metric2 = ... # Update & save the newest log if ( i % mle . train_config . log_every_steps ) == 0 : time_tick = { \"timestamp1\" : t + 1 } stats_tick = { \"metric1\" : metric1 , \"metric2\" : metric2 } # Store results mle . log . update_log ( time_tick , stats_tick , save = True ) return if __name__ == \"__main__\" : # Load in config for the experiment & run the simulation mle = MLExperiment () main ( mle ) .sh training script file You can also launch experiments which are not Python-based. In that case you cannot rely on the .hdf5 logging utilities or the hyper_log.pkl aggregation of search experiments. But this is not a problem as long as you set the no_results_logging boolean in the param_search_args[\"search_logging\"] .yaml configuration. #!/bin/sh # GET_CONFIGS_READY FOR BASH FILE! POSITIONAL =() while [[ $# -gt 0 ]] do key = \" $1 \" # Define commandline processing of arguments case $key in -exp_dir | --experiment_dir ) EXPERIMENT_DIR = \" $2 \" shift # past argument shift # past value ;; -config | --config_fname ) CONFIG_FNAME = \" $2 \" shift # past argument shift # past value ;; -seed | --seed_id ) SEED_ID = \" $2 \" shift # past argument shift # past value ;; esac done set -- \" ${ POSITIONAL [@] } \" # restore positional parameters for i in $( seq 0 ${ IMP_ITERS } ) do python main.py --config_fname ${ CONFIG_FNAME } --seed_id ${ SEED_ID } \\ --experiment_dir ${ EXPERIMENT_DIR } done","title":"Project Template"},{"location":"setup/template/#project-template","text":"In order to get a feeling for how an experiment based on the toolbox utilities may look like, checkout the project template repository .","title":"Project Template"},{"location":"setup/template/#general-directory-structure","text":"mle-project-template \u251c\u2500\u2500 configs: Training configurations (base and cluster searches) \u251c\u2500\u2500 train: .json training configuration \u251c\u2500\u2500 cluster: .yaml experiment configuration \u251c\u2500\u2500 docs: Some work-in-progress notes/documentation \u251c\u2500\u2500 experiments: Main directory storing results \u251c\u2500\u2500 notebooks: Sanity checks & result visualization \u251c\u2500\u2500 01_viz_results.ipynb: Visualize some results \u251c\u2500\u2500 utils: Helper functions (data generation, networks, training helpers) \u251c\u2500\u2500 cluster_exec.sh: Main training loop \u251c\u2500\u2500 mle_bash.sh: Main training loop as bash program \u251c\u2500\u2500 mle_python.py: Main training loop as python program \u251c\u2500\u2500 Readme.md: Documentation \u251c\u2500\u2500 requirements.txt: Dependencies","title":"General Directory Structure"},{"location":"setup/template/#yaml-experiment-configuration","text":"The .yaml file specifies what type of experiment you want to run. It consists of two core ingredients ( meta_job_args and single_job_args ) which have to be provided with every experiment type: # Meta Arguments: What job? What train .py file? # Base .json config? Where to store? meta_job_args : # Choose a project name used for logging your experiments project_name : \"<project_name>\" # Specifies what experiment to run. Can be one of the following: # 'single-config', 'multiple-configs', 'hyperparameter-search', # 'population-based-training' experiment_type : \"<experiment_type>\" base_train_fname : \"mle_python.py\" base_train_config : \"train/<base_config>.json\" experiment_dir : \"experiments/\" # Parameters for individual job: 2 logical cores single_job_args : job_name : \"ode\" num_logical_cores : 2 log_file : \"log\" err_file : \"err\" env_name : \"mle-toolbox\" They provide the most general information required to launch a single job that will execute mle_python.py on a resource with two logical cores. Additionally and depending on the settings you want to run please provide one of the following additional ingredients: Pre/Post-Processing : pre_processing_args and/or post_processing_args Multiple Configurations : multi_config_args Grid/Random Search/SMBO : param_search_args Population-Based Training : pbt_args","title":".yaml experiment configuration"},{"location":"setup/template/#json-training-configuration","text":"The .json file, on the other hand, specifies the train_config , log_config and (optionally) model_config , which are provided to a job. They can be easily accessed via the MLExperiment class instance (see below): { # Trai n i n g co nf igura t io n : Adap te d by hyperparame ter search \"train_config\" : { \"learning_rate\" : 3e-04 , ... }, # Model co nf igura t io n : Layer i nf o (i f t here was a net t o tra i n ) \"model_config\" : { \"num_hidden_layers\" : 2 , ... }, # Loggi n g co nf igura t io n : Wha t t o log/pri nt & tens orboard f ile na me \"log_config\" : { \"time_to_track\" : [ \"timestamp1\" ], # Var na mes o f t imes ta mps \"what_to_track\" : [ \"metric1\" , \"metric2\" ], # Var na mes o f s tats vars \"time_to_print\" : [ \"timestamp1\" ], # Time var na mes t o pri nt \"what_to_print\" : [ \"metric1\" ], # S tats var na mes t o pri nt \"print_every_k_updates\" : 1 , # How o ften t o pri nt \"overwrite_experiment_dir\" : 1 } # Whe t her t o overwri te exis t i n g dir } Importantly, when launching a grid search experiment the toolbox will copy the base configuration file and modify the variables in train_config which you intend to search over.","title":".json training configuration"},{"location":"setup/template/#py-training-script-file","text":"# Import MLE wrapper processing cmd inputs and logging from mle_toolbox import MLExperiment def main ( mle ): \"\"\" Main Training Loop Function. \"\"\" # Setup your experiment - e.g. build a network with `mle.model_config` model = build_model ( ** mle . model_config ) # Run the main training loop for t in range ( mle . train_config . num_steps ): # Perform the one-step optimization update metric1 , metric2 = ... # Update & save the newest log if ( i % mle . train_config . log_every_steps ) == 0 : time_tick = { \"timestamp1\" : t + 1 } stats_tick = { \"metric1\" : metric1 , \"metric2\" : metric2 } # Store results mle . log . update_log ( time_tick , stats_tick , save = True ) return if __name__ == \"__main__\" : # Load in config for the experiment & run the simulation mle = MLExperiment () main ( mle )","title":".py training script file"},{"location":"setup/template/#sh-training-script-file","text":"You can also launch experiments which are not Python-based. In that case you cannot rely on the .hdf5 logging utilities or the hyper_log.pkl aggregation of search experiments. But this is not a problem as long as you set the no_results_logging boolean in the param_search_args[\"search_logging\"] .yaml configuration. #!/bin/sh # GET_CONFIGS_READY FOR BASH FILE! POSITIONAL =() while [[ $# -gt 0 ]] do key = \" $1 \" # Define commandline processing of arguments case $key in -exp_dir | --experiment_dir ) EXPERIMENT_DIR = \" $2 \" shift # past argument shift # past value ;; -config | --config_fname ) CONFIG_FNAME = \" $2 \" shift # past argument shift # past value ;; -seed | --seed_id ) SEED_ID = \" $2 \" shift # past argument shift # past value ;; esac done set -- \" ${ POSITIONAL [@] } \" # restore positional parameters for i in $( seq 0 ${ IMP_ITERS } ) do python main.py --config_fname ${ CONFIG_FNAME } --seed_id ${ SEED_ID } \\ --experiment_dir ${ EXPERIMENT_DIR } done","title":".sh training script file"},{"location":"setup/video_tutorials/","text":"Video Tutorials Note : I gave a general overview talk on the setup and usage of the toolbox: TODO : You can watch the talk here . You can have a look at the slide deck here . 1. Motivation and Use-Case 2. Installation & Credentials Setup 3. Different mle <subcommand> mle run : Different experiment types mle retrieve : Getting your results (local or GCP) mle report : Generating .md / .html reports mle monitor : On different resources 4. Running Jobs on Gloud VMs Running Jobs with GCP and GCS storage 5. Analyzing Experiment Results Manual inspection of hyper_log and meta_log . 6. Hypothesis Testing","title":"Video Tutorials"},{"location":"setup/video_tutorials/#video-tutorials","text":"Note : I gave a general overview talk on the setup and usage of the toolbox: TODO : You can watch the talk here . You can have a look at the slide deck here .","title":"Video Tutorials"},{"location":"setup/video_tutorials/#1-motivation-and-use-case","text":"","title":"1. Motivation and Use-Case"},{"location":"setup/video_tutorials/#2-installation-credentials-setup","text":"","title":"2. Installation &amp; Credentials Setup"},{"location":"setup/video_tutorials/#3-different-mle-subcommand","text":"mle run : Different experiment types mle retrieve : Getting your results (local or GCP) mle report : Generating .md / .html reports mle monitor : On different resources","title":"3. Different mle &lt;subcommand&gt;"},{"location":"setup/video_tutorials/#4-running-jobs-on-gloud-vms","text":"Running Jobs with GCP and GCS storage","title":"4. Running Jobs on Gloud VMs"},{"location":"setup/video_tutorials/#5-analyzing-experiment-results","text":"Manual inspection of hyper_log and meta_log .","title":"5. Analyzing Experiment Results"},{"location":"setup/video_tutorials/#6-hypothesis-testing","text":"","title":"6. Hypothesis Testing"},{"location":"toolbox/experiments/","text":"Experiment Types Note : This page and content is still work in progress! Pre-/Post-Processing # Parameters for the pre-processing job pre_processing_args : processing_fname : \"<run_preprocessing>.py\" processing_job_args : num_logical_cores : 2 time_per_job : \"00:01:00\" extra_cmd_line_input : figures_dir : \"experiments/data\" # Parameters for the post-processing job post_processing_args : processing_fname : \"<run_postprocessing>.py\" processing_job_args : num_logical_cores : 2 time_per_job : \"00:01:00\" extra_cmd_line_input : figures_dir : \"experiments/figures\" Multiple Configurations & Seeds multi_config_args : config_fnames : - \"config_1.json\" - \"config_2.json\" num_seeds : 2 Hyperparameter Search Given a fixed training configuration file and the Python training script the only thing that has to be adapted for the different types of experiments is the meta configuration file. # Parameters specific to the hyperparameter search param_search_args : search_logging : reload_log : False verbose_log : True max_objective : True problem_type : \"final\" eval_metrics : \"test_loss\" search_resources : num_search_batches : 2 num_evals_per_batch : 2 num_seeds_per_eval : 1 search_config : search_type : \"grid\" # \"random\"/\"smbo\" search_schedule : \"sync\" search_params : categorical : opt_type : - \"Adam\" - \"RMSprop\" real : l_rate : begin : 1e-5 end : 1e-2 bins : 2 Population-Based Training # Parameters specific to the population-based training pbt_args : pbt_logging : max_objective : False eval_metric : \"test_loss\" pbt_resources : num_population_members : 10 num_total_update_steps : 2000 num_steps_until_ready : 500 num_steps_until_eval : 100 pbt_config : pbt_params : real : l_rate : begin : 1e-5 end : 1e-2 exploration : strategy : \"perturb\" selection : strategy : \"truncation\"","title":"Experiment Types"},{"location":"toolbox/experiments/#experiment-types","text":"Note : This page and content is still work in progress!","title":"Experiment Types"},{"location":"toolbox/experiments/#pre-post-processing","text":"# Parameters for the pre-processing job pre_processing_args : processing_fname : \"<run_preprocessing>.py\" processing_job_args : num_logical_cores : 2 time_per_job : \"00:01:00\" extra_cmd_line_input : figures_dir : \"experiments/data\" # Parameters for the post-processing job post_processing_args : processing_fname : \"<run_postprocessing>.py\" processing_job_args : num_logical_cores : 2 time_per_job : \"00:01:00\" extra_cmd_line_input : figures_dir : \"experiments/figures\"","title":"Pre-/Post-Processing"},{"location":"toolbox/experiments/#multiple-configurations-seeds","text":"multi_config_args : config_fnames : - \"config_1.json\" - \"config_2.json\" num_seeds : 2","title":"Multiple Configurations &amp; Seeds"},{"location":"toolbox/experiments/#hyperparameter-search","text":"Given a fixed training configuration file and the Python training script the only thing that has to be adapted for the different types of experiments is the meta configuration file. # Parameters specific to the hyperparameter search param_search_args : search_logging : reload_log : False verbose_log : True max_objective : True problem_type : \"final\" eval_metrics : \"test_loss\" search_resources : num_search_batches : 2 num_evals_per_batch : 2 num_seeds_per_eval : 1 search_config : search_type : \"grid\" # \"random\"/\"smbo\" search_schedule : \"sync\" search_params : categorical : opt_type : - \"Adam\" - \"RMSprop\" real : l_rate : begin : 1e-5 end : 1e-2 bins : 2","title":"Hyperparameter Search"},{"location":"toolbox/experiments/#population-based-training","text":"# Parameters specific to the population-based training pbt_args : pbt_logging : max_objective : False eval_metric : \"test_loss\" pbt_resources : num_population_members : 10 num_total_update_steps : 2000 num_steps_until_ready : 500 num_steps_until_eval : 100 pbt_config : pbt_params : real : l_rate : begin : 1e-5 end : 1e-2 exploration : strategy : \"perturb\" selection : strategy : \"truncation\"","title":"Population-Based Training"},{"location":"toolbox/mle_init/","text":"mle init - Setup The Toolbox TBC","title":"mle init - Setup The Toolbox"},{"location":"toolbox/mle_init/#mle-init-setup-the-toolbox","text":"TBC","title":"mle init - Setup The Toolbox"},{"location":"toolbox/mle_monitor/","text":"mle monitor - Monitor Resources","title":"mle monitor - Monitor Resources"},{"location":"toolbox/mle_monitor/#mle-monitor-monitor-resources","text":"","title":"mle monitor - Monitor Resources"},{"location":"toolbox/mle_report/","text":"mle report - Report Results TBC","title":"mle report - Report Results"},{"location":"toolbox/mle_report/#mle-report-report-results","text":"TBC","title":"mle report - Report Results"},{"location":"toolbox/mle_retrieve/","text":"mle retrieve - Retrieve Results","title":"mle retrieve - Retrieve Results"},{"location":"toolbox/mle_retrieve/#mle-retrieve-retrieve-results","text":"","title":"mle retrieve - Retrieve Results"},{"location":"toolbox/mle_run/","text":"mle run - Experiment Execution An experiment can be launched from the command line via: mle run <experiment_config>.yaml You can add several command line options, which can come in handy when debugging or if you want to launch multiple experiments sequentially: --no_welcome : Don't print welcome messages at experiment launch. --no_protocol : Do not record experiment in the PickleDB protocol database. --resource_to_run <resource> : Run the experiment on the specified resource. In the following we walk through the different types of supported experiments and show how to provide the necessary configuration specifications.","title":"mle run - Experiment Execution"},{"location":"toolbox/mle_run/#mle-run-experiment-execution","text":"An experiment can be launched from the command line via: mle run <experiment_config>.yaml You can add several command line options, which can come in handy when debugging or if you want to launch multiple experiments sequentially: --no_welcome : Don't print welcome messages at experiment launch. --no_protocol : Do not record experiment in the PickleDB protocol database. --resource_to_run <resource> : Run the experiment on the specified resource. In the following we walk through the different types of supported experiments and show how to provide the necessary configuration specifications.","title":"mle run - Experiment Execution"},{"location":"toolbox/mle_sync_gcs/","text":"mle sync-gcs - Sync GCS Results TBC","title":"mle sync-gcs - Sync GCS Results"},{"location":"toolbox/mle_sync_gcs/#mle-sync-gcs-sync-gcs-results","text":"TBC","title":"mle sync-gcs - Sync GCS Results"},{"location":"toolbox/mle_toolbox/","text":"MLE-Toolbox Overview What Does The mle-toolbox Provide? API for launching jobs on cluster/cloud computing platforms (Slurm, GridEngine, GCP). Common machine learning research experiment setups: Launching and collecting multiple random seeds in parallel/batches. Hyperparameter searches: Random, Grid, SMBO, Population-Based Training. Pre- and post-processing pipelines for data prep/result visualization. Automated report generation for hyperparameter searches. Storage of results and database in Google Cloud Storage Bucket. Resource monitoring with dashboard visualization. 5 Steps To Get Started Follow the installation instructions and set up your credentials/configurations. Read the docs to learn about the toolbox and .json & .yaml configuration files. Watch the YouTube Tutorials series for a hands-on walkthrough. Check out and re-run the examples to get comfortable. Run your own experiments using the template files, project and mle run . Core Commands of the Toolbox You are now ready to dive deeper into the specifics of job configuration and can start running your first experiments from the cluster (or locally on your machine) with the commands: Command Description \u23f3 mle init Start up an experiment. \ud83d\ude80 mle run Setup of credentials & toolbox settings. \ud83d\udda5\ufe0f mle monitor Monitor resource utilisation. \ud83d\udce5 mle retrieve Retrieve an experiment result. \ud83d\udc8c mle report Create an experiment report with figures. \ud83d\udd04 mle sync-gcs Extract all GCS-stored results to your local drive.","title":"MLE-Toolbox Overview"},{"location":"toolbox/mle_toolbox/#mle-toolbox-overview","text":"","title":"MLE-Toolbox Overview"},{"location":"toolbox/mle_toolbox/#what-does-the-mle-toolbox-provide","text":"API for launching jobs on cluster/cloud computing platforms (Slurm, GridEngine, GCP). Common machine learning research experiment setups: Launching and collecting multiple random seeds in parallel/batches. Hyperparameter searches: Random, Grid, SMBO, Population-Based Training. Pre- and post-processing pipelines for data prep/result visualization. Automated report generation for hyperparameter searches. Storage of results and database in Google Cloud Storage Bucket. Resource monitoring with dashboard visualization.","title":"What Does The mle-toolbox Provide?"},{"location":"toolbox/mle_toolbox/#5-steps-to-get-started","text":"Follow the installation instructions and set up your credentials/configurations. Read the docs to learn about the toolbox and .json & .yaml configuration files. Watch the YouTube Tutorials series for a hands-on walkthrough. Check out and re-run the examples to get comfortable. Run your own experiments using the template files, project and mle run .","title":"5 Steps To Get Started"},{"location":"toolbox/mle_toolbox/#core-commands-of-the-toolbox","text":"You are now ready to dive deeper into the specifics of job configuration and can start running your first experiments from the cluster (or locally on your machine) with the commands: Command Description \u23f3 mle init Start up an experiment. \ud83d\ude80 mle run Setup of credentials & toolbox settings. \ud83d\udda5\ufe0f mle monitor Monitor resource utilisation. \ud83d\udce5 mle retrieve Retrieve an experiment result. \ud83d\udc8c mle report Create an experiment report with figures. \ud83d\udd04 mle sync-gcs Extract all GCS-stored results to your local drive.","title":"Core Commands of the Toolbox"}]}