# Meta Arguments: What job? What train .py file? Base config? Where to store?
meta_job_args:
    project_name: examples
    job_type: "hyperparameter-search"
    base_train_fname: "run_ppo.py"
    base_train_config: "base_ppo_config.json"
    experiment_dir: "experiments/smbo/"

# Parameters specific to the hyperparameter search
param_search_args:
    search_type: "smbo"
    hyperlog_fname: "ppo_hyper_log.pkl"
    reload_log: False
    verbose_logging: True
    maximize_objective: True
    problem_type: "rl"
    eval_score_type: "rew_median"
    num_search_batches: 3
    num_iter_per_batch: 5
    num_evals_per_iter: 2
    params_to_search:
        categorical:
            opt_type:
                - "Adam"
                - "RMSprop"
                - "SGD"
        real:
            l_rate:
                begin: 1e-5
                end: 1e-2
                prior: "log-uniform"    # "uniform", "log-uniform"
    smbo_config:
        base_estimator: "GP"            # "GP", "RF", "ET", "GBRT"
        acq_function: "gp_hedge"        # "LCB", "EI", "PI", "gp_hedge"
        n_initial_points: 10

# Parameters specific to an individual job
single_job_args:
    job_name: "ppo"
    num_gpus: 0
    num_logical_cores: 2
    log_file: "log-ppo"
    err_file: "error-ppo"
    env_name: "multi-agent-cpu"
